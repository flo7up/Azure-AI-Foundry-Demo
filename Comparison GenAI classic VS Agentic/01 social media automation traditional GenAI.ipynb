{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "import azure.functions as func\n",
    "from openai import OpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "from hackernews import HackerNews\n",
    "import json\n",
    "\n",
    "# Use environment variables for API key\n",
    "keyvault_name = 'keyvaultforbot' # replace with your own keyvault\n",
    "client = SecretClient(f\"https://{keyvault_name}.vault.azure.net/\", DefaultAzureCredential())\n",
    "logging.info('Setting NewsAPI API Key')\n",
    "NEWSAPI_API_KEY = client.get_secret('newsapi-api-key').value\n",
    "\n",
    "logging.info('Setting OpenAI API Key')\n",
    "openaiclient = OpenAI(api_key=client.get_secret('openai-api-key').value)\n",
    "\n",
    "logging.info('Setting Function App API Key')\n",
    "API_KEY = client.get_secret('function-app-api').value\n",
    "\n",
    "##### Azure Blob Storage\n",
    "blobstorage_account_name = client.get_secret('blobstorage-account-name').value\n",
    "blobstorage_secret = client.get_secret('blobstorage-secret').value\n",
    "CONTAINER_NAME = 'botdata'\n",
    "CSV_NAME = 'news_log.csv'\n",
    "\n",
    "# check if container exists\n",
    "blob_service_client = BlobServiceClient(account_url=f\"https://{blobstorage_account_name}.blob.core.windows.net\", credential=blobstorage_secret)\n",
    "if not blob_service_client.get_container_client(CONTAINER_NAME).exists():\n",
    "    blob_service_client.create_container(CONTAINER_NAME)\n",
    "    logging.info(f'Container {CONTAINER_NAME} created')\n",
    "container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
    "logging.info ('Container client ready')\n",
    "\n",
    "def get_old_news():\n",
    "    blob_client = blob_service_client.get_blob_client(container=CONTAINER_NAME, blob=CSV_NAME)\n",
    "    data = blob_client.download_blob().content_as_text()\n",
    "    df = pd.read_csv(io.StringIO(data))\n",
    "    logging.info('Posts log retrieved from blob storage')\n",
    "    return df\n",
    "\n",
    "def save_posts_log(df):\n",
    "    # try:\n",
    "    blob_client = blob_service_client.get_blob_client(container=CONTAINER_NAME, blob=CSV_NAME)\n",
    "    blob_client.upload_blob(data=df.to_csv(index=False), overwrite=True)\n",
    "\n",
    "    print(f'File {CSV_NAME} saved to blob storage')\n",
    "    # except:\n",
    "    #     print(f'Error df {df}')\n",
    "    #     logging.info(f'Error df {df}')\n",
    "    #     print(f'Error saving {CSV_NAME}')\n",
    "    #     logging.info(f'Error {CSV_NAME}')\n",
    "    return True\n",
    "\n",
    "\n",
    "# #### NewsAPI\n",
    "# def fetch_newsapi_news(number=10):\n",
    "#     # Fetch tech news from NewsAPI\n",
    "#     url = f\"https://newsapi.org/v2/top-headlines?country=us&category=technology&category=business&category=science&apiKey={NEWSAPI_API_KEY}\"\n",
    "#     response = requests.get(url).json()\n",
    "#     news_items = response[\"articles\"]\n",
    "#     df = pd.DataFrame(news_items)\n",
    "#     df = df[[\"title\", \"description\", \"url\"]].dropna()\n",
    "#     return df.head(number)\n",
    "\n",
    "\n",
    "def fetch_main_content_from_url(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "# #### HackerNews\n",
    "# def fetch_hacker_news(number=50):\n",
    "#     hn = HackerNews()\n",
    "#     top_story_ids = hn.top_stories()\n",
    "\n",
    "#     news_list = []\n",
    "#     for story in top_story_ids[:number]:\n",
    "#         item = hn.item(story)\n",
    "#         if item.score > 100 and len(item.title) > 25:\n",
    "#             try:\n",
    "#                 url = item.url\n",
    "#                 try:\n",
    "#                     content = fetch_main_content_from_url(url)[0:3000] #fetches 3000 characters\n",
    "#                     logging.info(f'Content for {item.title} fetched')\n",
    "#                     logging.info(f'Content length: {len(content)}')\n",
    "#                 except:\n",
    "#                     content = ''\n",
    "#             except AttributeError:\n",
    "#                 url = \"\"\n",
    "        \n",
    "#             news_list.append({\n",
    "#                 'title': item.title,\n",
    "#                 'description': content,  # empty description\n",
    "#                 'url': url\n",
    "#             })\n",
    "\n",
    "#     df = pd.DataFrame(news_list)\n",
    "#     return df\n",
    "\n",
    "#### OpenAI Engine\n",
    "def openai_request(instructions, task, sample = [], temperature=0.5, model_engine='gpt-4o'):\n",
    "    prompt = [{\"role\": \"system\", \"content\": instructions }, \n",
    "              {\"role\": \"user\", \"content\": task }]\n",
    "    prompt = sample + prompt\n",
    "    response = openaiclient.chat.completions.create(model=model_engine, messages=prompt, temperature=temperature, max_tokens=400)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def select_relevant_news_prompt(news_articles, topics, n):    \n",
    "    instructions = f\"Please review the given list of news titles. Determine their relevance to an audience keen on the following themes: {topics}]. \\\n",
    "    Topics with low relevance: Stock market, Financial advice, military conflicts. \\\n",
    "    Provide a list of boolean values (True or False) corresponding to each title's relevance.\"\n",
    "    task =  f\"{news_articles}?\" \n",
    "    sample = [\n",
    "        {\"role\": \"user\", \"content\": f\"['new LLM model from Nvidia', \\\n",
    "            'Apples iPhone 15 Event Likely to Be Held on Sept 17', \\\n",
    "            'Release of b2 Game', \\\n",
    "            'XGBoost 3.0 improves Decision Forest Algorithms', \\\n",
    "            'New Zelda Game Now Available']\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"[True, True, False, True, False]\"},\n",
    "        {\"role\": \"user\", \"content\": f\"['Giant giraffs found in Africa', \\\n",
    "            'We tested the AMD Ryzen 8', \\\n",
    "            'LLM news: Rumors about OpenAI ChatGPT-5', \\\n",
    "            'Donald Trump to make a come back', \\\n",
    "            'Apple may be testing an M3 Mac Mini']\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"[False, True, True, False, True]\"},\n",
    "        {\"role\": \"user\", \"content\": f\"['War in Ukraine continues', \\\n",
    "            'Microsoft announces new analytics suite', \\\n",
    "            'Scikit-learn updates its API', \\\n",
    "            'Invest into these AI stocks', \\\n",
    "            'Alberta AG launches Virtual Assistant']\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"[False, True, True, False, True]\"},\n",
    "        {\"role\": \"user\", \"content\": f\"['Google bard with an upgrade', \\\n",
    "            'Boston dynamics presents atlass robot', \\\n",
    "            'Bosch invests into AI capabilities', \\\n",
    "            'How to evaluate the performance of a neural network', \\\n",
    "            'Amazon Sagemaker with new features', \\\n",
    "            'Meta to release new LLMA 2 model']\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"[True, True, True, True, True, True]\"}\n",
    "        ]\n",
    "    \n",
    "    return instructions, task, sample\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def check_previous_posts_relevance_json(title, old_posts):\n",
    "    instructions = \"Assess the novelty of a news title by comparing it with a list of previously discussed news topics. \" \\\n",
    "        \"Score the similarity risk on a scale from 0 to 5, where 0 indicates a completely new topic and 5 indicates an identical topic.\"\n",
    "    task = f\"Evaluate the novelty of '{title}' against these previous topics: {old_posts}\"\n",
    "    sample = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Evaluate the novelty of 'Nvidia launches new AI model' against these previous topics: \"\n",
    "                       \"[new AI model available from Nvidia, We Exploded the AMD Ryzen 7 7800X3D, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": '{\"Score\": 5, \"Explanation\": \"The title is identical with the first topic: new AI model available from Nvidia\"}'\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Evaluate the novelty of 'Big Explosion of an AMD Ryzen 7' against these previous topics: \"\n",
    "                       \"[Improving Mental Wellbeing Through Physical Activity, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": '{\"Score\": 0, \"Explanation\": \"Completely new topic\"}'\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Evaluate the novelty of 'new AI model available from Google' against these previous topics: \"\n",
    "                       \"[new AI model available from Nvidia, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": '{\"Score\": 2, \"Explanation\": \"The term new ai model is related to the first topic but since Nvidia and Google are separate companies, the topics are distinct\"}'\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Evaluate the novelty of 'What Really Made Geoffrey Hinton Into an AI Doomer - WIRED' against these previous topics: \"\n",
    "                       \"[Why AI's 'godfather' Geoffrey Hinton quit Google, new AI model available from Nvidia, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": '{\"Score\": 3, \"Explanation\": \"Somewhat related topics because Geoffrey Hinton is mentioned in the second title, however in a slightly different context\"}'\n",
    "        }\n",
    "    ]\n",
    "    return instructions, task, sample\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def call_tweet_function(title, description, url):\n",
    "    logging.info('Calling Azure Function App to Create Tweet')\n",
    "    # Define the Azure Function App URL\n",
    "    request_url = f\"https://relatalyfunc.azurewebsites.net/api/HttpCreateTwitterTweet?title={title}&description={description}&url={url}\"\n",
    "    headers = {\"x-functions-key\": API_KEY}\n",
    "    response = requests.post(request_url, headers=headers)\n",
    "\n",
    "    # Check the response status\n",
    "    if response.status_code == 200:\n",
    "        print(\"Azure Function App called successfully.\")\n",
    "    else:\n",
    "        print(\"Error calling Azure Function App.\")\n",
    "        print(\"Response:\", response.text)\n",
    "\n",
    "    return response.status_code\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def create_fact_tweet(input=\"\"):    \n",
    "    logging.info('Calling Azure Function App to Create Fact Tweet')\n",
    "    # Define the Azure Function App URL\n",
    "    request_url = f\"https://relatalyfunc.azurewebsites.net/api/HttpCreateTwitterFactTweet?input={input}\"\n",
    "    headers = {\"x-functions-key\": API_KEY}\n",
    "    response = requests.post(request_url, headers=headers)\n",
    "\n",
    "    # Check the response status\n",
    "    if response.status_code == 200:\n",
    "        print(\"Azure Function App called successfully.\")\n",
    "    else:\n",
    "        print(\"Error calling Azure Function App.\")\n",
    "        print(\"Response:\", response.text)\n",
    "    return response.status_code\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def previous_post_check(title, old_posts):\n",
    "    # Assuming check_previous_posts_relevance_json and openai_request are defined elsewhere\n",
    "    instructions, task, sample = check_previous_posts_relevance_json(title, old_posts)\n",
    "    response = openai_request(instructions, task, sample, 0.5, \"gpt-4o\") #gpt-4-1106-preview\n",
    "    logging.info('duplicate_check:' + str(response))\n",
    "    \n",
    "    try:\n",
    "        response_dict = json.loads(str(response).replace(\"'\", \"#\"))  # Parse the JSON string into a Python dictionary\n",
    "        score = response_dict.get('Score', 0)  # Extract the score, default to 0 if not found\n",
    "        explanation = response_dict.get('Explanation', 'No explanation provided')  # Optional: Extract explanation\n",
    "        logging.info(f'duplicate_check Score: {score}, Explanation: {explanation}')\n",
    "        return score\n",
    "    except json.JSONDecodeError as e:  # Catch JSON parsing errors\n",
    "        logging.error('Error in previous_post_check: Invalid JSON response. ' + str(e))\n",
    "        return 0\n",
    "    except Exception as e:  # Catch any other errors\n",
    "        logging.error('Error in previous_post_check: ' + str(e))\n",
    "        return 0\n",
    "\n",
    "\n",
    "#### Main Bot\n",
    "def main_bot(df):\n",
    "    df_old = get_old_news()\n",
    "    df_old = df_old.tail(16)\n",
    "    logging.info(df_old)\n",
    "    print(df_old)\n",
    "    # Fetch news data\n",
    "    \n",
    "    logging.info(df['title'])\n",
    "    \n",
    "    # Check the Relevance of the News and Filter those not relevant\n",
    "    relevant_topics =\"[machine learning, data science, robotics, openai, artificial intelligence, ai, neural networks, data mining, tensorflow, pytorch, nlp, data analytics, virtual assistants, chatbots, augmented reality, chatgpt, gpu, anthropic, microsoft, apple, nvidia]\"\n",
    "    instructions, task, sample = select_relevant_news_prompt(list(df['title']), relevant_topics, len(list(df['title'])))\n",
    "    temperature=0.0\n",
    "    relevance = openai_request(instructions, task, sample, temperature)\n",
    "    logging.info(len(list(df['title'])))\n",
    "    logging.info('relevance:' + relevance)\n",
    "    relevance_list = eval(relevance)\n",
    "    logging.info(len(relevance_list))\n",
    "\n",
    "    s = 0\n",
    "    df = df[relevance_list]\n",
    "    if len(df) > 0:\n",
    "        for index, row in df.iterrows():\n",
    "            if s == 1:\n",
    "                break\n",
    "            logging.info('info:' + row['title'])\n",
    "            title = row['title'].replace('\"', \"\").replace(\"'\", \"\").replace(\"’\", \"\").replace(\"“\", \"\").replace(\"”\", \"\")\n",
    "            title = title.replace(\"'\", \"\")\n",
    "            print(f\"title {title}\")\n",
    "            description = row['description']\n",
    "            url = row['url']            \n",
    "                                             \n",
    "            if (title not in df_old.title.values):\n",
    "                doublicate_check = previous_post_check(title, list(df_old.tail(10)['title']))\n",
    "                if doublicate_check < 3:\n",
    "                    # create tweet\n",
    "                    response = call_tweet_function(title, description, url)\n",
    "                    if (response >= 200) and (response < 300):\n",
    "                        print(f\"Tweeted: {title}\")\n",
    "                        #add title to the csv file  \n",
    "                        save_posts_log(pd.concat([df_old, pd.DataFrame({'title': [title]})], ignore_index=True))\n",
    "                        s += 1\n",
    "                    else:\n",
    "                        print(f\"Error: {response}\")\n",
    "                        logging.info(f\"Error: {response}\")\n",
    "                else: \n",
    "                    print(f\"Doublicate Context Check True: {title}\")\n",
    "                    logging.info(f\"Context Doublicate: {title}\")\n",
    "                    save_posts_log(pd.concat([df_old, pd.DataFrame({'title': [title]})], ignore_index=True))\n",
    "            else: \n",
    "                print(f\"Already tweeted: {title}\")\n",
    "                logging.info(f\"Already tweeted: {title}\")\n",
    "                \n",
    "    else: \n",
    "        print(\"No news articles found\")\n",
    "        logging.info(\"No news articles found\")\n",
    "        # 3% chance to tweet a fact\n",
    "        import random\n",
    "        if random.random() < 0.03:\n",
    "            fact = ' '\n",
    "            print(f\"Fact: {fact}\")\n",
    "            logging.info(f\"Fact: {fact}\")\n",
    "            response = create_fact_tweet(fact)\n",
    "            if response == 200:\n",
    "                print(f\"Tweeted: {fact}\")\n",
    "                logging.info(f\"Tweeted: {fact}\")\n",
    "            else:\n",
    "                print(f\"Error: {response}\")\n",
    "                logging.info(f\"Error: {response}\")\n",
    "\n",
    "def bingsearch(news_count=10):\n",
    "    # bing search example\n",
    "    # https://docs.microsoft.com/en-us/azure/cognitive-services/bing-web-search/quickstarts/python\n",
    "\n",
    "    # Add your Bing Search V7 subscription key and endpoint to your environment variables.\n",
    "    \n",
    "    endpoint = \"https://api.bing.microsoft.com/v7.0/news/search\"\n",
    "\n",
    "    # Query term(s) to search for.\n",
    "    query = \"Artificial Intelligence\"\n",
    "\n",
    "    # Construct a request\n",
    "    mkt = \"en-US\"\n",
    "    params = {'q': query, 'mkt': mkt, 'count': news_count}\n",
    "    \n",
    "    subscription_key = client.get_secret('bing-search-api').value\n",
    "    headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "    # Call the API\n",
    "    try:\n",
    "        response = requests.get(endpoint, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Print the response\n",
    "        jsonResponse = response.json()\n",
    "        print(json.dumps(jsonResponse, indent=4))\n",
    "\n",
    "    except Exception as ex:\n",
    "\n",
    "        raise ex\n",
    "\n",
    "\n",
    "\n",
    "    # get name and description for all news, then concatenate them and put them into a list\n",
    "    news = []\n",
    "    data = jsonResponse\n",
    "\n",
    "    news_list = []\n",
    "    for item in data['value']:\n",
    "        news_list.append({\n",
    "                    'title': item['name'],\n",
    "                    'description': item['description'],  # empty description\n",
    "                    'url': item['url']\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(news_list)\n",
    "    # show the full df content\n",
    "    #pd.set_option('display.max_colwidth', None)\n",
    "    logging.info('df')\n",
    "    # limit df to 10 records\n",
    "    df_limited = df.head(news_count)\n",
    "    return df_limited\n",
    "\n",
    "\n",
    "\n",
    "def main(mytimer: func.TimerRequest) -> None:\n",
    "    utc_timestamp = dt.datetime.utcnow().replace(\n",
    "        tzinfo=dt.timezone.utc).isoformat()\n",
    "\n",
    "    if mytimer.past_due:\n",
    "        logging.info('The timer is past due!')\n",
    "    # df_news_api = fetch_newsapi_news(5)\n",
    "    # main_bot(df_news_api)\n",
    "    # df_hacker_news = fetch_newsapi_news(10)\n",
    "    # main_bot(df_hacker_news)\n",
    "    df_bing = bingsearch(10)\n",
    "    main_bot(df_bing)\n",
    "\n",
    "    logging.info('Python timer trigger function ran at %s', utc_timestamp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
