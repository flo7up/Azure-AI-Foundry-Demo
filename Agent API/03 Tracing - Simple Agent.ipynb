{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tracing to work, you first need to link an Application Insights resource to your Azure AI Foundry Project. \n",
    "# This is just a basic example of how to do that.\n",
    "# You can find more information about tracing in the following links:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/trace\n",
    "# https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/visualize-traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_4bUgZa08CkwOEdrTGQlckGIc', 'object': 'thread.message', 'created_at': 1744016031, 'assistant_id': 'asst_eHZCO2yQyDDxssMxTCCJxybz', 'thread_id': 'thread_bEMZM0RC6XoZbYg9YmcLprak', 'run_id': 'run_eLTTMtRRIz1pZPLoOKl5LLma', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': \"As of October 2023, here is an overview of the latest and most relevant developments in AI:\\n\\n### 1. **OpenAI Announcements**\\n   - OpenAI has integrated new features into ChatGPT, including tools like **DALL·E 3**, enabling users to create images directly through text prompts. Additionally, **multimodal capabilities** (e.g., voice interactions and file analysis) are being rolled out in the ChatGPT app for Pro users.\\n   - OpenAI has formed partnerships with businesses, focusing on enterprise applications of AI and introducing ChatGPT for businesses to simplify workflows.\\n\\n### 2. **Anthropic's Claude AI**\\n   - Anthropic, an AI safety-focused company, recently launched **Claude 3**, a competitor to GPT models. Claude is recognized for its focus on ethical responses and reduced hallucination risks.\\n   - They've positioned Claude to handle larger input sizes, appealing to corporations for improved document analysis and summarization.\\n\\n### 3. **Google's Gemini AI**\\n   - Google DeepMind is preparing to launch its **Gemini AI**, which promises to deliver advanced multimodal capabilities (text, image, and perhaps video). Gemini is expected to rival GPT-4 and is being integrated into Google services like Bard and Workspace.\\n   - Google Bard itself has been refining its conversational AI, adding features like verifying the accuracy of responses and interacting with other Google apps.\\n\\n### 4. **Generative AI in Business**\\n   - Multiple companies, including Adobe, Salesforce, and Zoom, have rolled out generative AI tools to improve communication, design, and operational efficiency. Adobe, for example, has integrated AI capabilities into its Creative Cloud suite with **Firefly**.\\n   - Microsoft continues to expand its **Copilot suite**, integrating AI into Office products to assist in content generation, data analysis, and more.\\n\\n### 5. **AI Regulation**\\n   - Governments globally are addressing AI regulation, with the **European Union's AI Act** taking the lead on defining compliance requirements for high-risk AI applications. Companies like OpenAI and Meta are actively engaging policymakers to shape regulations effectively.\\n   - The U.S. Senate held hearings with top AI executives to discuss regulatory frameworks, emphasizing transparency, ethical deployment, and accountability.\\n\\n### 6. **Meta's AI Release**\\n   - **Meta** recently launched **Llama 2**, its open-access large language model, to compete against OpenAI and Google. It is tailored for research and commercial use, with open weights to encourage innovation.\\n   - Meta introduced AI-powered tools in Instagram and WhatsApp, including **AI avatars** and generative content features.\\n\\n### 7. **Generative AI in Art and Creativity**\\n   - DALL·E 3 and other models are pushing the boundaries of generative AI for art. New advancements are addressing copyright concerns and improving prompt-based outputs tailored for professional designers and creators.\\n\\n### 8. **Major Concerns in AI**\\n   - Top issues in AI revolve around **AI misrepresentation** (aka hallucinations), data privacy, and copyright concerns. Industry leaders are actively researching ways to make generative models more reliable and adaptable.\\n   - **Deepfake concerns** continue to grow, particularly with AI voice synthesis and video manipulations. Governments are working on legal safeguards to counter misuse in politics and media.\\n\\n### 9. **Breakthroughs in Healthcare AI**\\n   - AI models are improving **medical diagnostics**, drug discovery, and predictive analytics for patient care. Companies like Google Health and others are showing promising results in detecting diseases early using AI systems.\\n\\n### 10. **AI and Climate Research**\\n   - The use of AI for climate modeling and disaster prediction has gained traction, with tools being developed to assist in wildfire forecasting, flood management, and clean energy optimization.\\n\\nIf you'd like to dive deeper into any of these topics, let me know!\", 'annotations': []}}], 'attachments': [], 'metadata': {}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from opentelemetry import trace\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from dotenv import load_dotenv\n",
    "from opentelemetry.trace.status import Status, StatusCode\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_CONNECTION_STRING = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "logging.getLogger(\"azure\").setLevel(logging.DEBUG)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1) Load Project Client and Set Up Tracing\n",
    "# --------------------------------------------------------------------\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=AzureCliCredential(),\n",
    "    conn_str=PROJECT_CONNECTION_STRING\n",
    ")\n",
    "\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "if not application_insights_connection_string:\n",
    "    print(\"Application Insights was not enabled for this project.\")\n",
    "    print(\"Enable it via the 'Tracing' tab in your AI Foundry project page.\")\n",
    "    exit()\n",
    "\n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "project_client.telemetry.enable()\n",
    "\n",
    "# Timestamped scenario name\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tracing_name = f\"sample_agents_basics_with_azure_monitor_tracing_{timestamp}\"\n",
    "scenario = os.path.basename(tracing_name)\n",
    "tracer = trace.get_tracer(\"my_notebook_tracer\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2) Helper for Exception Tracking\n",
    "# --------------------------------------------------------------------\n",
    "def track_exception(span, exc):\n",
    "    span.set_status(Status(StatusCode.ERROR, str(exc)))\n",
    "    span.record_exception(exc)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3) Run AI Project Pipeline\n",
    "# --------------------------------------------------------------------\n",
    "def run_ai_project_pipeline():\n",
    "    instructions = \"\"\"\n",
    "    You are a helpful assistant with the goal to give an overview of the latest relevant AI news\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(scenario) as span:\n",
    "        try:\n",
    "            with project_client:\n",
    "                # Agent creation\n",
    "                with tracer.start_as_current_span(\"create_agent\") as s:\n",
    "                    agent = project_client.agents.create_agent(\n",
    "                        model=\"gpt-4o\",\n",
    "                        name=\"my-agent\",\n",
    "                        instructions=instructions\n",
    "                    )\n",
    "                    s.set_attribute(\"agent.id\", agent.id)\n",
    "\n",
    "                # Thread creation\n",
    "                with tracer.start_as_current_span(\"create_thread\") as s:\n",
    "                    thread = project_client.agents.create_thread()\n",
    "                    s.set_attribute(\"thread.id\", thread.id)\n",
    "\n",
    "                # User message creation\n",
    "                with tracer.start_as_current_span(\"create_message\") as s1:\n",
    "                    message_text = \"Hello! I'd like to have the latest AI news.\"\n",
    "                    message = project_client.agents.create_message(\n",
    "                        thread_id=thread.id,\n",
    "                        role=\"user\",\n",
    "                        content=message_text\n",
    "                    )\n",
    "                    s1.set_attribute(\"input.message_content\", message_text)\n",
    "                    s1.set_attribute(\"output.message_id\", message.id)\n",
    "\n",
    "                # Run agent\n",
    "                with tracer.start_as_current_span(\"create_and_process_run\") as s:\n",
    "                    run = project_client.agents.create_and_process_run(\n",
    "                        thread_id=thread.id,\n",
    "                        agent_id=agent.id\n",
    "                    )\n",
    "                    s.set_attribute(\"run.status\", run.status)\n",
    "                    if run.status == \"failed\":\n",
    "                        s.set_status(Status(StatusCode.ERROR, \"Run failed\"))\n",
    "                        s.set_attribute(\"run.error\", str(run.last_error))\n",
    "                        logging.error(f\"Run failed: {run.last_error}\")\n",
    "                    else:\n",
    "                        logging.info(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "                # List messages\n",
    "                \n",
    "                \n",
    "                messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "                assistant_response = messages.get_last_message_by_role(\"assistant\")\n",
    "                assistant_response_text = assistant_response.content[0].text.value\n",
    "                logging.info(f\"Assistant response: {assistant_response_text}\")\n",
    "                s.set_attribute(\"output.assistant_response\", assistant_response_text)\n",
    "                return assistant_response\n",
    "\n",
    "                # Delete agent\n",
    "                with tracer.start_as_current_span(\"delete_agent\") as s:\n",
    "                    project_client.agents.delete_agent(agent.id)\n",
    "                    s.set_attribute(\"deleted.agent_id\", agent.id)\n",
    "                    logging.info(\"Deleted agent successfully.\")\n",
    "        except Exception as e:\n",
    "            track_exception(span, e)\n",
    "            raise\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 4) Local Test Entry Point\n",
    "# --------------------------------------------------------------------\n",
    "assistant_response = run_ai_project_pipeline()\n",
    "assistant_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a version where each run of the pipeline is tracked in a single separate top-level span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from opentelemetry import trace\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from dotenv import load_dotenv\n",
    "from opentelemetry.trace.status import Status, StatusCode\n",
    "\n",
    "load_dotenv()\n",
    "logging.getLogger(\"azure\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Get timestamped trace name early\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tracing_name = f\"sample_agents_basics_with_azure_monitor_tracing_{timestamp}\"\n",
    "scenario = os.path.basename(tracing_name)\n",
    "tracer = trace.get_tracer(\"my_notebook_tracer\")\n",
    "\n",
    "def run_ai_project_pipeline():\n",
    "    with tracer.start_as_current_span(scenario) as span:\n",
    "\n",
    "        try:\n",
    "            # Move project client creation *inside* the span\n",
    "            PROJECT_CONNECTION_STRING = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "            project_client = AIProjectClient.from_connection_string(\n",
    "                credential=AzureCliCredential(),\n",
    "                conn_str=PROJECT_CONNECTION_STRING\n",
    "            )\n",
    "\n",
    "            # Enable Azure Monitor tracing\n",
    "            application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "            if not application_insights_connection_string:\n",
    "                print(\"Application Insights was not enabled for this project.\")\n",
    "                exit()\n",
    "            configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "            project_client.telemetry.enable()\n",
    "\n",
    "            instructions = \"\"\"\n",
    "            You are a helpful assistant with the goal to give an overview of the latest relevant AI news\n",
    "            \"\"\"\n",
    "            with project_client:\n",
    "                with tracer.start_as_current_span(\"create_agent\") as s:\n",
    "                    agent = project_client.agents.create_agent(\n",
    "                        model=\"gpt-4o\",\n",
    "                        name=\"my-agent\",\n",
    "                        instructions=instructions\n",
    "                    )\n",
    "                    s.set_attribute(\"agent.id\", agent.id)\n",
    "\n",
    "                with tracer.start_as_current_span(\"create_thread\") as s:\n",
    "                    thread = project_client.agents.create_thread()\n",
    "                    s.set_attribute(\"thread.id\", thread.id)\n",
    "\n",
    "                with tracer.start_as_current_span(\"create_message\") as s:\n",
    "                    msg_text = \"Hello! I'd like to have the latest AI news.\"\n",
    "                    message = project_client.agents.create_message(\n",
    "                        thread_id=thread.id,\n",
    "                        role=\"user\",\n",
    "                        content=msg_text\n",
    "                    )\n",
    "                    s.set_attribute(\"input.message_content\", msg_text)\n",
    "                    s.set_attribute(\"output.message_id\", message.id)\n",
    "\n",
    "                with tracer.start_as_current_span(\"create_and_process_run\") as s:\n",
    "                    run = project_client.agents.create_and_process_run(\n",
    "                        thread_id=thread.id,\n",
    "                        agent_id=agent.id\n",
    "                    )\n",
    "                    s.set_attribute(\"run.status\", run.status)\n",
    "\n",
    "                with tracer.start_as_current_span(\"list_messages\") as s:\n",
    "                    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "                    for msg in messages[\"data\"]:\n",
    "                        s.add_event(f\"{msg['role']}: {msg['content'][0]['text']['value']}\")\n",
    "\n",
    "                with tracer.start_as_current_span(\"delete_agent\") as s:\n",
    "                    project_client.agents.delete_agent(agent.id)\n",
    "                    s.set_attribute(\"deleted.agent_id\", agent.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            span.set_status(Status(StatusCode.ERROR, str(e)))\n",
    "            span.record_exception(e)\n",
    "            raise\n",
    "\n",
    "run_ai_project_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
