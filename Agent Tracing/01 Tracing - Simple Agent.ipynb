{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tracing to work, you first need to link an Application Insights resource to your Azure AI Foundry Project. \n",
    "# This is just a basic example of how to do that.\n",
    "# You can find more information about tracing in the following links:\n",
    "# https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/trace\n",
    "# https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/visualize-traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant response: Sure! Here’s an overview of the latest developments in AI as of October 2023:\n",
      "\n",
      "### **1. OpenAI's Next-Generation Updates**\n",
      "OpenAI is reportedly working on a successor to GPT-4, dubbed GPT-5 or refined improvements to GPT-4. While GPT-5 has not been officially released, OpenAI recently introduced enhancements like \"custom GPTs,\" allowing users to customize models for specific use cases directly within their ecosystem.\n",
      "\n",
      "Additionally, OpenAI launched **ChatGPT Enterprise**, focused on providing businesses with robust AI solutions, featuring advanced security, unlimited GPT-4 access, and analysis tools for company workflows.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Google DeepMind Introduces Gemini AI**\n",
      "Google DeepMind recently rolled out its _Gemini 1_ series, aiming to compete with GPT-4 models. Gemini integrates advanced reinforcement learning techniques combined with cutting-edge NLP capabilities. DeepMind plans to scale this model for enterprise use alongside Google Workspace apps.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Meta’s Open-Sourced LLM: LLaMA 2 Expansion**\n",
      "Meta’s **LLaMA 2** (Large Language Model Meta AI) continues to gain adoption from developers due to its open-source accessibility. Meta announced plans to expedite its AI research into multimodal capabilities and further democratization of AI tech, building additional competitive features that rival proprietary options like OpenAI and Google.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. AI Safety Announcements: Global AI Regulation Efforts**\n",
      "Governments and organizations globally are intensifying efforts to regulate AI. Key developments include:\n",
      "- **The UK AI Safety Summit 2023**: A global forum set in November, aiming to address the existential risks of AI and establish guidelines for safer development.\n",
      "- **US Executive Action**: President Biden enacted an **AI executive order** in October 2023, demanding rigorous assessments of potential cybersecurity and safety risks in AI systems.\n",
      "- Discussions at the **United Nations** have amplified concerns around AI governance for autonomous weapons, misinformation, and social impact.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. NVIDIA Maintains Dominance in AI Hardware**\n",
      "NVIDIA, the leader in AI-focused GPUs (Graphics Processing Units), launched a new chip series optimizing large-scale AI training tasks. The H200 and H100 chips are widely used by OpenAI, Google, and other firms pushing forward generative AI research.\n",
      "\n",
      "Additionally, NVIDIA’s software ecosystem, especially CUDA and TensorRT, continues to empower breakthroughs in generative AI by reducing costs.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Adobe & Generative AI Art Creation Tools**\n",
      "Adobe expanded its offerings with **Firefly**, a generative AI tool embedded within Photoshop and Illustrator. Recent updates include iterative improvements in text-to-image generation, tailored for creative professionals. This helps bridge the technical gap by enabling users to use AI intuitively for content creation.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. AI-Powered Autonomous Agents on the Rise**\n",
      "Advanced autonomous agent frameworks like **AutoGPT**, **BabyAGI**, and others are making waves. These AI-powered tools aim to replicate human-like decision-making across complex tasks, significantly amplifying discussions around their applications in business automation while sparking conversation around ethical guidelines.\n",
      "\n",
      "---\n",
      "\n",
      "### **8. AI in Healthcare Advances**\n",
      "AI’s role in medicine continues to expand, with models designed for early disease detection, treatment personalization, and drug discovery. Recent breakthroughs include applications of large language models in analyzing medical imaging and patient records to assist in diagnostics with unprecedented accuracy.\n",
      "\n",
      "---\n",
      "\n",
      "Would you like to dive deeper into any specific topic? Let me know!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from opentelemetry import trace\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from dotenv import load_dotenv\n",
    "from opentelemetry.trace.status import Status, StatusCode\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_CONNECTION_STRING = os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    "logging.getLogger(\"azure\").setLevel(logging.DEBUG)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1) Load Project Client and Set Up Tracing\n",
    "# --------------------------------------------------------------------\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=AzureCliCredential(),\n",
    "    conn_str=PROJECT_CONNECTION_STRING\n",
    ")\n",
    "\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "if not application_insights_connection_string:\n",
    "    print(\"Application Insights was not enabled for this project.\")\n",
    "    print(\"Enable it via the 'Tracing' tab in your AI Foundry project page.\")\n",
    "    exit()\n",
    "\n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "project_client.telemetry.enable()\n",
    "\n",
    "# Timestamped scenario name\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tracing_name = f\"sample_agents_basics_with_azure_monitor_tracing_{timestamp}\"\n",
    "scenario = os.path.basename(tracing_name)\n",
    "tracer = trace.get_tracer(\"my_notebook_tracer\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2) Helper for Exception Tracking\n",
    "# --------------------------------------------------------------------\n",
    "def track_exception(span, exc):\n",
    "    span.set_status(Status(StatusCode.ERROR, str(exc)))\n",
    "    span.record_exception(exc)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3) Run AI Project Pipeline\n",
    "# --------------------------------------------------------------------\n",
    "def run_ai_project_pipeline():\n",
    "    instructions = \"\"\"\n",
    "    You are a helpful assistant with the goal to give an overview of the latest relevant AI news\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(scenario) as span:\n",
    "        try:\n",
    "            with project_client:\n",
    "                # Agent creation\n",
    "                with tracer.start_as_current_span(\"create_agent\") as s:\n",
    "                    agent = project_client.agents.create_agent(\n",
    "                        model=\"gpt-4o\",\n",
    "                        name=\"my-agent\",\n",
    "                        instructions=instructions\n",
    "                    )\n",
    "                    s.set_attribute(\"agent.id\", agent.id)\n",
    "\n",
    "                # Thread creation\n",
    "                with tracer.start_as_current_span(\"create_thread\") as s:\n",
    "                    thread = project_client.agents.create_thread()\n",
    "                    s.set_attribute(\"thread.id\", thread.id)\n",
    "\n",
    "                # User message creation\n",
    "                with tracer.start_as_current_span(\"create_message\") as s1:\n",
    "                    message_text = \"Hello! I'd like to have the latest AI news.\"\n",
    "                    message = project_client.agents.create_message(\n",
    "                        thread_id=thread.id,\n",
    "                        role=\"user\",\n",
    "                        content=message_text\n",
    "                    )\n",
    "                    s1.set_attribute(\"input.message_content\", message_text)\n",
    "                    s1.set_attribute(\"output.message_id\", message.id)\n",
    "\n",
    "                # Run agent\n",
    "                with tracer.start_as_current_span(\"create_and_process_run\") as s:\n",
    "                    run = project_client.agents.create_and_process_run(\n",
    "                        thread_id=thread.id,\n",
    "                        agent_id=agent.id\n",
    "                    )\n",
    "                    s.set_attribute(\"run.status\", run.status)\n",
    "                    if run.status == \"failed\":\n",
    "                        s.set_status(Status(StatusCode.ERROR, \"Run failed\"))\n",
    "                        s.set_attribute(\"run.error\", str(run.last_error))\n",
    "                        logging.error(f\"Run failed: {run.last_error}\")\n",
    "                    else:\n",
    "                        logging.info(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "                # List messages\n",
    "                with tracer.start_as_current_span(\"list_messages\") as s:\n",
    "                    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "                    for msg in messages[\"data\"]:\n",
    "                        role = msg[\"role\"]\n",
    "                        s.add_event(f\"Message from: {role}\")\n",
    "                        if role == \"assistant\":\n",
    "                            for part in msg[\"content\"]:\n",
    "                                if part[\"type\"] == \"text\":\n",
    "                                    assistant_message = part[\"text\"][\"value\"]\n",
    "                                    logging.info(\"Assistant response: \" + assistant_message)\n",
    "                                    print(\"Assistant response: \" + assistant_message)\n",
    "                                    s.set_attribute(\"Assistant response\", assistant_message)\n",
    "                        elif role == \"system\":\n",
    "                            for part in msg[\"content\"]:\n",
    "                                if part[\"type\"] == \"text\":\n",
    "                                    logging.info(\"System says: \" + part[\"text\"][\"value\"])\n",
    "                                    print(\"System says: \" + part[\"text\"][\"value\"])\n",
    "                        elif role == \"user\":\n",
    "                            logging.info(f\"User says: {msg['content'][0]['text']['value']}\")\n",
    "\n",
    "                # Delete agent\n",
    "                with tracer.start_as_current_span(\"delete_agent\") as s:\n",
    "                    project_client.agents.delete_agent(agent.id)\n",
    "                    s.set_attribute(\"deleted.agent_id\", agent.id)\n",
    "                    logging.info(\"Deleted agent successfully.\")\n",
    "        except Exception as e:\n",
    "            track_exception(span, e)\n",
    "            raise\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 4) Local Test Entry Point\n",
    "# --------------------------------------------------------------------\n",
    "run_ai_project_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
